{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here are some imports that are used along this notebook\n",
    "import math\n",
    "import itertools\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "gt0 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext, Row\n",
    "\n",
    "# Creating local SparkContext with 8 threads and SQLContext based on it\n",
    "sc = pyspark.SparkContext(master='local[8]')\n",
    "sc.setLogLevel('INFO')\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading train data\n",
    "t0 = time()\n",
    "train_df = load_dataset(train_nsl_kdd_dataset_path)\n",
    "\n",
    "# Fitting preparation pipeline\n",
    "labels_mapping_model = labels_mapping_pipeline.fit(train_df)\n",
    "\n",
    "# Transforming labels column and adding id column\n",
    "train_df = labels_mapping_model.transform(train_df).withColumn('id', sql.monotonically_increasing_id())\n",
    "\n",
    "train_df = train_df.cache()\n",
    "print(train_df.count())\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22544\n",
      "0.778895378112793\n"
     ]
    }
   ],
   "source": [
    "# Loading test data\n",
    "t0 = time()\n",
    "test_df = load_dataset(test_nsl_kdd_dataset_path)\n",
    "\n",
    "# Transforming labels column and adding id column\n",
    "test_df = labels_mapping_model.transform(test_df).withColumn('id', sql.monotonically_increasing_id())\n",
    "\n",
    "test_df = test_df.cache()\n",
    "print(test_df.count())\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. One Hot Encoding for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding (OHE) is used for treating categorical variables. Custom function is created for demonstration purposes. However, it could be easily replaced by PySpark OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ohe_vec(cat_dict, row):\n",
    "    vec = np.zeros(len(cat_dict))\n",
    "    vec[cat_dict[row]] = float(1.0)\n",
    "    return vec.tolist()\n",
    "\n",
    "def ohe(df, nominal_col):\n",
    "    categories = (df.select(nominal_col)\n",
    "                    .distinct()\n",
    "                    .rdd.map(lambda row: row[0])\n",
    "                    .collect())\n",
    "    \n",
    "    cat_dict = dict(zip(categories, range(len(categories))))\n",
    "    \n",
    "    udf_ohe_vec = udf(lambda row: ohe_vec(cat_dict, row), \n",
    "                      StructType([StructField(cat, DoubleType(), False) for cat in categories]))\n",
    "    \n",
    "    df = df.withColumn(nominal_col + '_ohe', udf_ohe_vec(col(nominal_col))).cache()\n",
    "    \n",
    "    nested_cols = [nominal_col + '_ohe.' + cat for cat in categories]\n",
    "    ohe_cols = [nominal_col + '_' + cat for cat in categories]\n",
    "        \n",
    "    for new, old in zip(ohe_cols, nested_cols):\n",
    "        df = df.withColumn(new, col(old))\n",
    "\n",
    "    df = df.drop(nominal_col + '_ohe')\n",
    "                   \n",
    "    return df, ohe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125973\n",
      "13.566007614135742\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "train_ohe_cols = []\n",
    "\n",
    "train_df, train_ohe_col0 = ohe(train_df, nominal_cols[0])\n",
    "train_ohe_cols += train_ohe_col0\n",
    "\n",
    "train_df, train_ohe_col1 = ohe(train_df, nominal_cols[1])\n",
    "train_ohe_cols += train_ohe_col1\n",
    "\n",
    "train_df, train_ohe_col2 = ohe(train_df, nominal_cols[2])\n",
    "train_ohe_cols += train_ohe_col2\n",
    "\n",
    "binary_cols += train_ohe_cols\n",
    "\n",
    "train_df = train_df.cache()\n",
    "print(train_df.count())\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=selectFeaturesByAR(ar_dict, 0.01), outputCol='raw_features')\n",
    "indexer = VectorIndexer(inputCol='raw_features', outputCol='indexed_features', maxCategories=2)\n",
    "\n",
    "prep_pipeline = Pipeline(stages=[assembler, indexer])\n",
    "prep_model = prep_pipeline.fit(scaled_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125973\n",
      "22544\n",
      "1.659245252609253\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "scaled_train_df = (prep_model\n",
    "        .transform(scaled_train_df)\n",
    "        .select('id', 'indexed_features', 'labels2_index', 'labels2', 'labels5_index', 'labels5')\n",
    "        .cache())\n",
    "\n",
    "scaled_test_df = (prep_model \n",
    "        .transform(scaled_test_df)\n",
    "        .select('id', 'indexed_features','labels2_index', 'labels2', 'labels5_index', 'labels5')\n",
    "        .cache())\n",
    "\n",
    "print(scaled_train_df.count())\n",
    "print(scaled_test_df.count())\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100840\n",
      "25133\n"
     ]
    }
   ],
   "source": [
    "split = (scaled_train_df.randomSplit([0.8, 0.2], seed=seed))\n",
    "\n",
    "scaled_train_df = split[0].cache()\n",
    "scaled_cv_df = split[1].cache()\n",
    "\n",
    "print(scaled_train_df.count())\n",
    "print(scaled_cv_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25133\n",
      "22544\n"
     ]
    }
   ],
   "source": [
    "res_cv_df = scaled_cv_df.select(col('id'), col('labels2_index'), col('labels2'), col('labels5')).cache()\n",
    "res_test_df = scaled_test_df.select(col('id'), col('labels2_index'), col('labels2'), col('labels5')).cache()\n",
    "prob_cols = []\n",
    "pred_cols = []\n",
    "\n",
    "print(res_cv_df.count())\n",
    "print(res_test_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different metrics from sklearn are used for evaluating results. The most important from them for this task are False positive Rate, Detection Rate and F1 score. \n",
    "As evaluating via sklearn requires to collect predicted and label columns to the driver, it will be replaced with PySpark metrics later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def printCM(cm, labels):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels])\n",
    "    # Print header\n",
    "    print(\" \" * columnwidth, end=\"\\t\")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\"\\t\")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"%{0}s\".format(columnwidth) % label1, end=\"\\t\")\n",
    "        for j in range(len(labels)):\n",
    "            print(\"%{0}d\".format(columnwidth) % cm[i, j], end=\"\\t\")\n",
    "        print()\n",
    "\n",
    "def getPrediction(e):\n",
    "    return udf(lambda row: 1.0 if row >= e else 0.0, DoubleType())\n",
    "        \n",
    "def printReport(resDF, probCol, labelCol='labels2_index', e=None, labels=['normal', 'attack']):\n",
    "    if (e):\n",
    "        predictionAndLabels = list(zip(*resDF.rdd\n",
    "                                       .map(lambda row: (1.0 if row[probCol] >= e else 0.0, row[labelCol]))\n",
    "                                       .collect()))\n",
    "    else:\n",
    "        predictionAndLabels = list(zip(*resDF.rdd\n",
    "                                       .map(lambda row: (row[probCol], row[labelCol]))\n",
    "                                       .collect()))\n",
    "    \n",
    "    cm = metrics.confusion_matrix(predictionAndLabels[1], predictionAndLabels[0])\n",
    "    printCM(cm, labels)\n",
    "    print(\" \")\n",
    "    print(\"Accuracy = %g\" % (metrics.accuracy_score(predictionAndLabels[1], predictionAndLabels[0])))\n",
    "    print(\"AUC = %g\" % (metrics.roc_auc_score(predictionAndLabels[1], predictionAndLabels[0])))\n",
    "    print(\" \")\n",
    "    print(\"False Alarm Rate = %g\" % (cm[0][1]/(cm[0][0] + cm[0][1])))\n",
    "    print(\"Detection Rate = %g\" % (cm[1][1]/(cm[1][1] + cm[1][0])))\n",
    "    print(\"F1 score = %g\" % (metrics.f1_score(predictionAndLabels[1], predictionAndLabels[0], labels)))\n",
    "    print(\" \")\n",
    "    print(metrics.classification_report(predictionAndLabels[1], predictionAndLabels[0]))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. KMeans clustering with Random Forest Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of the first approach is to clusterize data into clusters and then train different Random Forest classifiers for each of the clusters. As Random Forest returns probabilities, it is possible to improve detection rate for a new types of attacks by adjusting threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As KMeans cannot truly handle binary/categorical features only numeric features are used for clustarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans_prob_col = 'kmeans_rf_prob'\n",
    "kmeans_pred_col = 'kmeans_rf_pred'\n",
    "\n",
    "prob_cols.append(kmeans_prob_col)\n",
    "pred_cols.append(kmeans_pred_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.780123472213745\n"
     ]
    }
   ],
   "source": [
    "# KMeans clustrering\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "t0 = time()\n",
    "kmeans_slicer = VectorSlicer(inputCol=\"indexed_features\", outputCol=\"features\", \n",
    "                             names=list(set(selectFeaturesByAR(ar_dict, 0.1)).intersection(numeric_cols)))\n",
    "\n",
    "kmeans = KMeans(k=8, initSteps=25, maxIter=100, featuresCol=\"features\", predictionCol=\"cluster\", seed=seed)\n",
    "\n",
    "kmeans_pipeline = Pipeline(stages=[kmeans_slicer, kmeans])\n",
    "\n",
    "kmeans_model = kmeans_pipeline.fit(scaled_train_df)\n",
    "\n",
    "kmeans_train_df = kmeans_model.transform(scaled_train_df).cache()\n",
    "kmeans_cv_df = kmeans_model.transform(scaled_cv_df).cache()\n",
    "kmeans_test_df = kmeans_model.transform(scaled_test_df).cache()\n",
    "\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function for describing the contents of the clusters \n",
    "def getClusterCrosstab(df, clusterCol='cluster'):\n",
    "    return (df.crosstab(clusterCol, 'labels2')\n",
    "              .withColumn('count', col('attack') + col('normal'))\n",
    "              .withColumn(clusterCol + '_labels2', col(clusterCol + '_labels2').cast('int'))\n",
    "              .sort(col(clusterCol +'_labels2').asc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+------+-----+\n",
      "|cluster_labels2|attack|normal|count|\n",
      "+---------------+------+------+-----+\n",
      "|              0|  6659| 46448|53107|\n",
      "|              1|  9125|  2266|11391|\n",
      "|              2|   626|    61|  687|\n",
      "|              3| 27742|   101|27843|\n",
      "|              4|  2670|  5073| 7743|\n",
      "|              5|     1|     0|    1|\n",
      "|              6|     0|    24|   24|\n",
      "|              7|     2|    42|   44|\n",
      "+---------------+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_crosstab = getClusterCrosstab(kmeans_train_df).cache()\n",
    "kmeans_crosstab.show(n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustres are splitted into two categories. Frist category contains clusters that have both 'attack' and 'normal' connections and have more than 25 connections. For the first category Random Forest classifiers are aplied. Second category contains all other clusters and maps cluster to 'attack' or 'normal' based on majority. All clusters that contains less or equal than 25 connections are treated as outliers and are mapped to 'attack' type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2\n",
      "{5: 1.0, 6: 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [53107, 0.1253883668819553],\n",
       " 1: [11391, 0.8010710209814766],\n",
       " 2: [687, 0.9112081513828238],\n",
       " 3: [27843, 0.9963725173293108],\n",
       " 4: [7743, 0.3448275862068966],\n",
       " 7: [44, 0.045454545454545456]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for splitting clusters\n",
    "def splitClusters(crosstab):\n",
    "    exp = ((col('count') > 25) & (col('attack') > 0) & (col('normal') > 0))\n",
    "\n",
    "    cluster_rf = (crosstab\n",
    "        .filter(exp).rdd\n",
    "        .map(lambda row: (int(row['cluster_labels2']), [row['count'], row['attack']/row['count']]))\n",
    "        .collectAsMap())\n",
    "\n",
    "    cluster_mapping = (crosstab\n",
    "        .filter(~exp).rdd\n",
    "        .map(lambda row: (int(row['cluster_labels2']), 1.0 if (row['count'] <= 25) | (row['normal'] == 0) else 0.0))\n",
    "        .collectAsMap())\n",
    "    \n",
    "    return cluster_rf, cluster_mapping\n",
    "\n",
    "kmeans_cluster_rf, kmeans_cluster_mapping = splitClusters(kmeans_crosstab)\n",
    "\n",
    "print(len(kmeans_cluster_rf), len(kmeans_cluster_mapping))\n",
    "print(kmeans_cluster_mapping)\n",
    "kmeans_cluster_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# This function returns Random Forest models for provided clusters\n",
    "def getClusterModels(df, cluster_rf):\n",
    "    cluster_models = {}\n",
    "\n",
    "    labels_col = 'labels2_cl_index'\n",
    "    labels2_indexer.setOutputCol(labels_col)\n",
    "\n",
    "    rf_slicer = VectorSlicer(inputCol=\"indexed_features\", outputCol=\"rf_features\", \n",
    "                             names=selectFeaturesByAR(ar_dict, 0.05))\n",
    "\n",
    "    for cluster in cluster_rf.keys():\n",
    "        t1 = time()\n",
    "        rf_classifier = RandomForestClassifier(labelCol=labels_col, featuresCol='rf_features', seed=seed,\n",
    "                                               numTrees=500, maxDepth=20, featureSubsetStrategy=\"sqrt\")\n",
    "        \n",
    "        rf_pipeline = Pipeline(stages=[labels2_indexer, rf_slicer, rf_classifier])\n",
    "        cluster_models[cluster] = rf_pipeline.fit(df.filter(col('cluster') == cluster))\n",
    "        print(\"Finished %g cluster in %g ms\" % (cluster, time() - t1))\n",
    "        \n",
    "    return cluster_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This utility function helps to get predictions/probabilities for the new data and return them into one dataframe\n",
    "def getProbabilities(df, probCol, cluster_mapping, cluster_models):\n",
    "    pred_df = (sqlContext.createDataFrame([], StructType([\n",
    "                    StructField('id', LongType(), False),\n",
    "                    StructField(probCol, DoubleType(), False)])))\n",
    "    \n",
    "    udf_map = udf(lambda cluster: cluster_mapping[cluster], DoubleType())\n",
    "    pred_df = pred_df.union(df.filter(col('cluster').isin(list(cluster_mapping.keys())))\n",
    "                            .withColumn(probCol, udf_map(col('cluster')))\n",
    "                            .select('id', probCol))\n",
    "\n",
    "                                       \n",
    "    for k in cluster_models.keys():\n",
    "        maj_label = cluster_models[k].stages[0].labels[0]\n",
    "        udf_remap_prob = udf(lambda row: float(row[0]) if (maj_label == 'attack') else float(row[1]), DoubleType())\n",
    "\n",
    "        pred_df = pred_df.union(cluster_models[k]\n",
    "                         .transform(df.filter(col('cluster') == k))\n",
    "                         .withColumn(probCol, udf_remap_prob(col('probability')))\n",
    "                         .select('id', probCol))\n",
    "\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0 cluster in 197.395 ms\n",
      "Finished 1 cluster in 18.5909 ms\n",
      "Finished 2 cluster in 1.40909 ms\n",
      "Finished 3 cluster in 12.9506 ms\n",
      "Finished 4 cluster in 3.07712 ms\n",
      "Finished 7 cluster in 0.999874 ms\n",
      "234.42527198791504\n"
     ]
    }
   ],
   "source": [
    "# Training Random Forest classifiers for each of the clusters\n",
    "t0 = time()\n",
    "kmeans_cluster_models = getClusterModels(kmeans_train_df, kmeans_cluster_rf)\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25133\n",
      "17.96238350868225\n"
     ]
    }
   ],
   "source": [
    "# Getting probabilities for CV data\n",
    "t0 = time()\n",
    "res_cv_df = (res_cv_df.drop(kmeans_prob_col)\n",
    "             .join(getProbabilities(kmeans_cv_df, kmeans_prob_col, kmeans_cluster_mapping, kmeans_cluster_models), 'id')\n",
    "             .cache())\n",
    "\n",
    "print(res_cv_df.count())\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22544\n",
      "16.670548915863037\n"
     ]
    }
   ],
   "source": [
    "# Getting probabilities for Test data\n",
    "t0 = time()\n",
    "res_test_df = (res_test_df.drop(kmeans_prob_col)\n",
    "               .join(getProbabilities(kmeans_test_df, kmeans_prob_col, kmeans_cluster_mapping, kmeans_cluster_models), 'id')\n",
    "               .cache())\n",
    "\n",
    "print(res_test_df.count())\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As CV data is from the same distribution as the train data it isn't needed to adjust threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \tnormal\tattack\t\n",
      "normal\t 13316\t    12\t\n",
      "attack\t    26\t 11779\t\n",
      " \n",
      "Accuracy = 0.998488\n",
      "AUC = 0.998449\n",
      " \n",
      "False Alarm Rate = 0.00090036\n",
      "Detection Rate = 0.997798\n",
      "F1 score = 0.99839\n",
      " \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     13328\n",
      "        1.0       1.00      1.00      1.00     11805\n",
      "\n",
      "avg / total       1.00      1.00      1.00     25133\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "printReport(res_cv_df, kmeans_prob_col, e=0.5, labels=labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because test data is from the different distribution and it is expected to face unseen attack types, it makes sence to adjust a probability threshold to something like 0.01 for attack connections (0.99 for normal connections). For this approach it gives around ~98-99% Detection Rate with around ~14-15% of False Alarm Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \tnormal\tattack\t\n",
      "normal\t  8262\t  1449\t\n",
      "attack\t   182\t 12651\t\n",
      " \n",
      "Accuracy = 0.927653\n",
      "AUC = 0.918303\n",
      " \n",
      "False Alarm Rate = 0.149212\n",
      "Detection Rate = 0.985818\n",
      "F1 score = 0.939442\n",
      " \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.85      0.91      9711\n",
      "        1.0       0.90      0.99      0.94     12833\n",
      "\n",
      "avg / total       0.93      0.93      0.93     22544\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "printReport(res_test_df, kmeans_prob_col, e=0.01, labels=labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25133\n",
      "22544\n",
      "16.63809633255005\n"
     ]
    }
   ],
   "source": [
    "# Adding prediction columns based on chosen thresholds into result dataframes\n",
    "t0 = time()\n",
    "res_cv_df = res_cv_df.withColumn(kmeans_pred_col, getPrediction(0.5)(col(kmeans_prob_col))).cache()\n",
    "res_test_df = res_test_df.withColumn(kmeans_pred_col, getPrediction(0.01)(col(kmeans_prob_col))).cache()\n",
    "\n",
    "print(res_cv_df.count())\n",
    "print(res_test_df.count())\n",
    "print(time() - t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
